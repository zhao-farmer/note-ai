import{_ as e,c as a,o as t,a0 as l}from"./chunks/framework.DqNHTjo5.js";const o="/note-ai/application/picture/sd-webui/other/001.png",s="/note-ai/application/picture/sd-webui/other/002.png",p="/note-ai/application/picture/sd-webui/other/003.png",n="/note-ai/application/picture/sd-webui/other/004.png",r="/note-ai/application/picture/sd-webui/other/005.gif",c="/note-ai/application/picture/sd-webui/other/006.gif",F=JSON.parse('{"title":"AnimateDiff动画","description":"","frontmatter":{},"headers":[],"relativePath":"markdown/application/picture/sd-webui/other/01.md","filePath":"markdown/application/picture/sd-webui/other/01.md"}'),d={name:"markdown/application/picture/sd-webui/other/01.md"};function h(u,i,m,f,k,b){return t(),a("div",null,i[0]||(i[0]=[l('<h1 id="animatediff动画" tabindex="-1">AnimateDiff动画 <a class="header-anchor" href="#animatediff动画" aria-label="Permalink to &quot;AnimateDiff动画&quot;">​</a></h1><p>早起的半AI视频解决方案都是基于逐帧重绘的思路，但是具有闪烁严重以及耗时漫长等缺陷。</p><p>由于帧之间包含的运动元素是具有规律以及关联性的，AnimateDiff基于此对视频片段进行训练，让AI学习不同类型视频的运动方式，单独训练出了一个运动模块：Motion Module。</p><h2 id="_1-插件安装" tabindex="-1">1. 插件安装 <a class="header-anchor" href="#_1-插件安装" aria-label="Permalink to &quot;1. 插件安装&quot;">​</a></h2><p>同样，直接在管理页面 之中安装此插件即可.以便于后续更新</p><p>插件网址：<a href="https://github.com/continue-revolution/sd-webui-animatediff/" target="_blank" rel="noreferrer">https://github.com/continue-revolution/sd-webui-animatediff/</a></p><p><img src="'+o+'" alt="" data-fancybox="gallery"></p><h2 id="_2-模型下载与配置" tabindex="-1">2. 模型下载与配置 <a class="header-anchor" href="#_2-模型下载与配置" aria-label="Permalink to &quot;2. 模型下载与配置&quot;">​</a></h2><h3 id="_2-1-模型下载" tabindex="-1">2.1 模型下载 <a class="header-anchor" href="#_2-1-模型下载" aria-label="Permalink to &quot;2.1 模型下载&quot;">​</a></h3><p>使用AnimateDiff之前需要去HuggingFace下载一下对应的运动大模型：</p><p>模型地址：<a href="https://huggingface.co/guoyww/animatediff/tree/main" target="_blank" rel="noreferrer">https://huggingface.co/guoyww/animatediff/tree/main</a></p><p><img src="'+s+`" alt="" data-fancybox="gallery"></p><h3 id="_2-2-文件放入指定文件夹" tabindex="-1">2.2 文件放入指定文件夹 <a class="header-anchor" href="#_2-2-文件放入指定文件夹" aria-label="Permalink to &quot;2.2 文件放入指定文件夹&quot;">​</a></h3><p>下载好AnimateDiff模型后将把模型放到对应的文件夹里面。</p><p>运动模型放到&quot;…\\extensions\\sd-webui-animatediff\\model&quot;目录下面，</p><p>LoRA模型放到&quot;…\\models\\lora&quot;目录下面。</p><h3 id="_2-3-修改webui-user-bat批处理文件" tabindex="-1">2.3 修改webui-user.bat批处理文件 <a class="header-anchor" href="#_2-3-修改webui-user-bat批处理文件" aria-label="Permalink to &quot;2.3 修改webui-user.bat批处理文件&quot;">​</a></h3><p>animatediff插件安装好之后，要正常运行还需要修改stable diffusion 的启动批处理文件的参数，参考如下：</p><div class="language-sh vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">sh</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">@echo</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> off</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">set</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> PYTHON=</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">set</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> GIT=</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">set</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> VENV_DIR=</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">set</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> COMMANDLINE_ARGS=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> --autolaunch</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> --theme</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> dark</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> --xformers</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> --no-gradio-queue</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> --disable-safe-unpickle</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">REM</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> --medvram（显存不足时添加该参数）</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">call</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> webui.bat</span></span></code></pre></div><ul><li>其中的<code>–disable-safe-unpickle</code>是在选择SDXL大模型和<code>Motion module</code>选择<code>mm_sdxl_v10_beta.ckpt</code>这个模型的时候需要添加的参数；</li><li>而<code>–medvram</code>参数则是在你的显存小于8G的情况下，需要添加的参数。</li></ul><h2 id="_3-参数解析" tabindex="-1">3. 参数解析 <a class="header-anchor" href="#_3-参数解析" aria-label="Permalink to &quot;3. 参数解析&quot;">​</a></h2><p><img src="`+p+'" alt="" data-fancybox="gallery"></p><ol><li><p>运动模块（Motion module）</p><p>这里显示的就是我们前面下载的三个主模型</p><ul><li>mm_sd_v15.ckpt：这是第一代的SD1.5版本的运动模块，配合SD1.5版本的checkpoint模型使用；</li><li>mm_sd_v15_v2.ckpt：这是第二代的SD1.5版本的运动模型，配合SD1.5版本的checkpoint模型使用，也是现在使用最多的模块；</li><li>mm_sdxl_v10_beta.ckpt：这是SDXL版本的运动模块，配合SDXL的checkpoint模型使用，当选择这个模块的时候，需要修改<code>webui-user.bat</code>文件的参数，增加<code>–disable-safe-unpickle</code>；</li></ul></li><li><p>保存格式（Save format）</p><p>输出的格式,至少选择<code>GIF</code>|<code>MP4</code>|<code>WEBP</code>|<code>WEBM</code>|<code>PNG</code>之一。如果您需要信息文本，请选中<code>TXT</code>，该信息文本将与输出 GIF 位于同一目录中。信息文本也可以通过stable-diffusion-webui/params.txt所有格式访问和输出。</p><ul><li>您可以使用gifsicle或palette来优化 GIF 。转至Settings/AnimateDiff启用它们。</li><li>您可以通过 设置 WEBP 的质量和无损Settings/AnimateDiff。</li><li>如果您使用API​​，通过将<code>PNG</code>添加到format，您可以将所有帧保存到文件系统，而无需返回所有帧。如果您希望 API 返回所有帧，请添加Frame到format列表。</li></ul></li><li><p>帧数（Number of frames） 生成的动画或者视频文件的总帧数</p><ul><li>如果输入 0（默认）： <ul><li>如果通过<code>视频源</code>提交视频或通过<code>视频路径</code>输入视频路径，或启用任何批量ControlNet，帧数将是视频中的帧数（如果提交了多个视频，则使用最短的视频）。</li><li>否则，帧数将根据<code>Context batch size</code>的如下描述。</li></ul></li><li>如果输入的数字小于<code>Context batch size</code>且不为0： <ul><li>你将从整个生成过程中获得<code>Number of frames</code>前1帧作为输出的GIF。所有后续帧不会出现在生成的GIF中，但会像往常一样保存为PNG格式。不要将<code>Number of frames</code>设置为小于<code>Context batch size</code>的数字（除0外）</li></ul></li></ul></li><li><p>帧率（FPS）</p><p>每秒帧数，即每秒显示的帧数（图像）。</p><p>如果以每秒 8 帧的速度生成 16 帧，则 GIF 的持续时间为 2 秒。如果您提交源视频，您的 FPS 将与源视频相同。</p></li><li><p>显示循环次数（Display loop number）</p><p>GIF 播放的次数。值0表示 GIF 永远不会停止播放。保持默认0即可！</p></li><li><p>上下文批量大小（Context batch size）</p><p>一次将有多少帧传递到运动模块中。</p><ul><li><p>SD1.5 运动模块采用 16 帧进行训练，因此当帧数设置为 时会给出最佳结果16。</p></li><li><p>SDXL HotShotXL 运动模块改为使用 8 帧进行训练。对于 V1 / HotShotXL 运动模块选择 [1, 24]，对于 V2 / AnimateDiffXL 运动模块选择 [1, 32]。</p></li></ul></li><li><p>闭环（Closed loop）</p><p>意味着此扩展将尝试使最后一帧与第一帧相同。</p><ul><li><p>当Number of frames&gt;Context batch size时，包括当 ControlNet 启用且源视频帧数 &gt;Context batch size且Number of frames= 0 时，AnimateDiff 无限上下文生成器将执行闭环。</p></li><li><p>当Number of frames&lt;=Context batch size时，AnimateDiff 无限上下文生成器将不起作用。只有当您选择<code>A</code>时，AnimateDiff 才会将反转的帧列表附加到原始帧列表以形成闭环。</p></li><li><p>有关每个选择的说明，请参阅下文：</p><ul><li>N意味着绝对没有闭环 – 如果Number of frames的值小于Context batch size且不为0 ，这是唯一可用的选项。</li><li>R-P意味着扩展将尝试减少闭环上下文的数量。提示行程（prompt traveling）不会被插补为闭环。</li><li>R+P意味着扩展将尝试减少闭环上下文的数量。提示行程（prompt traveling）将被插补为闭环。</li><li>A意味着扩展将积极尝试使最后一帧与第一帧相同。提示行程（prompt traveling）将被插补为闭环。</li></ul></li></ul></li><li><p>步幅（Stride） <code>步幅</code>（Stride）是最大运动步幅的设置，用 2 的幂表示（默认：1）。</p><ul><li><p>由于无限上下文生成器的限制，该参数仅在Number of frames&gt;Context batch size时有效，或者当 ControlNet 启用且源视频帧数 &gt;Context batch size且Number of frames为 0 时有效。</p></li><li><p>Stride只有当为 1时，才能完全没有闭环。</p></li><li><p>对于每个 1≤2 ≤1≤2i≤ Stride，无限上下文生成器将尝试使相隔2 2i的帧在时间上保持一致。例如，如果Stride为4 ，并且Number of frames 为8，它将使以下帧在时间上保持一致：</p><ul><li>Stride== 1: [0, 1, 2, 3, 4, 5, 6, 7]</li><li>Stride== 2: [0, 2, 4, 6], [1, 3, 5, 7]</li><li>Stride== 4: [0, 4], [1, 5], [2, 6], [3, 7]</li></ul></li></ul></li><li><p>重叠（Overlap）</p><p>上下文中重叠的帧数</p><p>如果重叠为 -1（默认）：您的重叠将为Context batch size// 4</p><p>由于无限上下文生成器的限制，该参数仅在Number of frame&gt;Context batch size时有效，包括当 ControlNet 启用且源视频帧数 &gt;Context batch size且Number of frames为 0 时有效</p></li><li><p>帧插值（Frame Interpolation）</p><p>使用 Deforum 的 FILM 实现在帧之间进行插值。需要 Deforum 扩展。</p><p><img src="'+n+'" alt="" data-fancybox="gallery"></p><ul><li><p>这个参数有两个选项<code>off</code>和<code>FILM</code></p><ul><li>如果选择<code>off</code>，则关闭<code>Frame Interpolation</code>功能，同时后面的<code>Interp X</code>参数将失效！</li><li>如果选择<code>FILM</code>，则开启<code>Frame Interpolation</code>功能，同时后面的<code>Interp X</code>将产生效果！</li></ul></li><li><p>FILM 选项会影响生成动画的平滑度。当您单击<code>FILM</code>时，它会激活帧插值，用于平滑动画。Interp X 参数允许您控制添加的额外帧的数量：</p><ol><li>使用FILM进行平滑处理：点击FILM可以平滑动画。通过调整Interp X参数，可以控制添加的额外帧数。默认情况下，Interp X设置为10，意味着每个原始帧将增加10个额外帧。</li><li>视频帧数增加：使用FILM后，视频的总帧数会显著增加。例如，原本有32帧的视频，使用FILM后帧数会增加到311帧，大约为每个原始帧增加9.7帧。</li><li>调整FPS以获得更流畅的播放：为了抵消由增加帧数引起的慢动作效果，可以调整视频的帧率（FPS）。提高FPS可以使视频播放得更快、更流畅。例如，将FPS从8增加到24，可以将视频时长缩短到12秒，同时保持平滑。进一步将FPS增加到70，可以将视频时长恢复到原来的4秒，同时保持通过FILM创建的插值帧，实现平滑的播放效果​​​​。</li></ol></li><li><p>总结来说，AnimateDiff的FILM选项通过添加额外帧来生成更平滑的动画，并通过调整Interp X和FPS设置，控制动画的平滑度和播放速度。</p></li></ul></li><li><p>视频源（Video source） [可选]</p></li></ol><p>ControlNet V2V的视频源文件。您必须启用 ControlNet。它将成为您无需提交控制图像或 ControlNet 面板路径即可启用的所有 ControlNet 单元的源代码控制。您当然可以通过Single Image选项卡提交一张控制图像或通过选项卡提交一个输入目录Batch，这将覆盖此视频源输入并照常工作。</p><ol start="12"><li>视频路径（Video path）[可选]</li></ol><p>ControlNet V2V源帧的文件夹，但优先级低于Video source。您必须启用 ControlNet。它将成为您无需提交控制映像或 ControlNet 路径即可启用的所有 ControlNet 单元的源代码控制。您当然可以通过Single Image选项卡提交一个控制图像或通过选项卡提交一个输入目录Batch，这将覆盖此视频路径输入并照常工作。 对于想要修复视频的人：输入包含两个子文件夹image和maskControlNet 修复单元的文件夹。这两个子文件夹应包含相同数量的图像。该扩展将按照相同的顺序匹配它们。使用我的Segment Anything扩展可以让您的生活变得更加轻松。</p><h2 id="_4-生成图" tabindex="-1">4. 生成图 <a class="header-anchor" href="#_4-生成图" aria-label="Permalink to &quot;4. 生成图&quot;">​</a></h2><ul><li>真实模型</li></ul><p><img src="'+r+'" alt="" data-fancybox="gallery"></p><ul><li>动画模型</li></ul><p><img src="'+c+'" alt="" data-fancybox="gallery"></p>',31)]))}const _=e(d,[["render",h]]);export{F as __pageData,_ as default};
