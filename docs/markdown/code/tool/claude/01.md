
# 一、初始化Claude

## 1.1 引言

### 1.1.1 为什么不用Cursor了

​	Cursor是一款基于人工智能的代码编辑器，旨在帮助开发人员编写代码，并于AI进行实时互动，提供写代码建议、错误检测和自动补全功能。支持多种编程语言（如Python、JavaScript、Java等）

​	现在AI开发工具在开发中的能力和重要性越来越高，Cursor的高能力让很多人趋之若鹜，但是Cursor计价规则的**黑箱模式**、朝令夕改、费用上调又让开发者们感到无奈且遗憾。

​	Cursor首先是修改了免费用户的使用权限，从不限制模型到只能使用gpt4.1模型，再到只能使用Auto模式；其次修改了每个月充值了 20美元的Pro用户的权限，首先是从每月500次快速，额度用尽后转为慢速，变成了无次数限制，但是快速慢速混用，可以通过额外付费避免慢速。其实这倒是也能接受，无非是每天可能会有几个任务卡住几分钟或者十几分钟而已。但是最近一次的计费规则修改堪称抽象，Pro用户每月只能发起总价$20的请求。下图是我上个月的用量：

![](/code/tool/claude/001.png)

​	原来这些模型这么贵。那$20想必也是稍纵即逝。这种朝令夕改、不公布计价细节的行为让人无法接受，Cursor是其母公司的唯一产品，其并没有一线大厂的一言九鼎和尊重用户的品质，因此，选择一个合适的替代品十分重要

### 1.1.2 为什么使用Claude Code

​	Calude（克劳德）Code 是由 Anthropic 开发的官方 CLI 工具，用于协助用户处理软件工程任务。 Anthropic 发现了Cursor的成功后，开发了Claude Code作为Cursor的竞品。Claude Code是一个革命性的AI编程工具，它将强大的Claude AI直接集成到您的开发环境中。

```
Anthropic是一家位于美国加州旧金山的人工智能股份有限公司，成立于2021年。该公司是一家人工智能安全和研究公司，致力于构建可靠、可解释和可操纵的AI系统。Anthropic公司开发了聊天机器人Claude，提出的“宪法AI原则”。 
2025年2月25日，Anthropic宣布推出Claude 3.7 Sonnet，称这是其迄今为止最智能的模型，也是市场上首款混合推理模型。北京时间2025年5月23日，Anthropic正式推出Claude 4系列大模型。
2025年4月，入选《2025福布斯AI 50榜单》
```

与传统的代码编辑器插件不同，Claude Code在终端中运行，具有以下特点：

* 智能代码理解: 深度理解您的项目结构和代码逻辑
* 自然语言交互: 用普通话描述需求，AI自动执行编程任务
* 全项目上下文: 理解整个代码库的架构和依赖关系
* 安全可靠: 直接连接Anthropic API，所有操作在本地执行
* Git集成: 智能的版本控制操作和历史分析

除此之外，Claude Code还有以下优势：

- 原生Claude模型，没有Cursor暗加的种种故意为了耗费提问次数的提示词，能按照需求制定完善的执行计划
- 可按token计费，而不是提问次数。这样无论问题大小尽管提问，按需付费。
- 可接入其他模型，这是很重要的一点，因为只要是符合Anthropic框架的LLM都可以接入Claude Code平台
- 安装简单，调用国内最新模型价格低廉。后续会详细说明安装流程

### 1.1.3 应用场景举例

```shell
# 场景一：代码编写和修改
"添加一个用户登录功能"
"修复这个函数的bug"
"重构这段代码提高性能"

# 场景二：代码分析和理解
"这个项目是做什么的？"
"解释这个函数的工作原理"
"找出性能瓶颈在哪里"

# 场景三：测试和调试
"运行所有测试并修复失败的部分"
"添加单元测试覆盖这个模块"
"分析为什么这个测试失败了"

# 场景四：Git操作
"提交当前更改"
"创建新分支进行功能开发"
"查看最近的提交历史"

# 其他......
```

* 项目分析

![](/code/tool/claude/002.png)

* 添加功能

![](/code/tool/claude/003.png)

* 项目性能分析

![](/code/tool/claude/004.png)


## 1.2 Claude 的安装与使用

​Claude Code的最新版本终于支持Windows系统了，不用再用wsl去进行繁琐的配置了！

```
WSL（Windows Subsystem for Linux）是微软开发的Windows子系统，允许用户在Windows 10/11上原生运行Linux二进制文件，无需虚拟机或双系统启动。
```

1. 必备组件

    - Git 版本控制工具
    - Node.js 18+ 版本（推荐使用最新LTS版本）

2. 安装claude-code

        
    - 通过npm包管理器直接安装

        ```bash
        npm install -g @anthropic-ai/claude-code
        ```

    - 安装完成后验证是否安装成功

        ```bash
        claude --version
        ```

        ![](/code/tool/claude/008.png)

3. 使用claude-code-router(ssr)绕过验证

    - [github地址](https://github.com/musistudio/claude-code-router)

    - 安装插件

        ```sh
        npm install -g @musistudio/claude-code-router
        ```
4. 如果是在外网 可以直接运行此命令

    ```sh
    claude
    ```

## 1.3 Claude Code Router 使用

### 引言

本教程将手把手教你在 **Claude Code Router（CCR）** 中配置 **Gemini 2.5 Pro**、**DeepSeek-V3.1**、**GLM-4.5**、**Kimi-K2** 与 **Qwen3-Coder（魔搭 ModelScope）** 的**直连 API**，并实现**UI 下拉/命令一键切换**。按照本文，初学者可走完 **“获取密钥 → CCR UI 配置 → 首次通连测试”** 的最短路径。

**说明**：Claude Code 原生只“认” **Anthropic 格式**接口（`/v1/messages`），而 **CCR** 在后端完成协议转换，适配 **OpenAI 兼容**或特定厂商 API。因此**本文的 Provider 多采用 OpenAI 兼容的 `/v1/chat/completions` 或厂商专用端点**；个别模型（如 Gemini）需在 CCR 中启用专用 `transformer`。

如果你打算使用 **Anthropic 格式** URL，请在 **Transformer** 中选择 **Anthropic**，并确保 Base URL **以 `/v1/messages` 结尾**；若不选择该转换器，则使用 **OpenAI 兼容**的 `/v1/chat/completions` 等端点并选择 **openai**。

**Anthropic 格式常用示例**

*   DeepSeek：`https://api.deepseek.com/anthropic/v1/messages`
*   智谱：`https://open.bigmodel.cn/api/anthropic/v1/messages`

> 小贴士：有些环境会自动给 `…/anthropic` 追加 `/v1/messages`；为避免“重复拼接”导致的 404，**在 CCR 里把 Base URL 直接写到 `/v1/messages` 结尾最稳妥**。若走 OpenAI 兼容模式，请改用各家提供的 `/chat/completions` 等端点并在 Transformer 选择 **openai**。


### 1.3.1 环境准备与启动

先安装 **Claude Code** 与 **Claude Code Router**：

```bash
npm install -g @anthropic-ai/claude-code
npm install -g @musistudio/claude-code-router
```

启动 CCR 的图形界面（UI）：

```bash
ccr ui
```

执行后会在本地开启服务并自动打开 Web 界面（默认：`http://localhost:3456`）。  
**提示：** 若不希望把密钥写入配置文件，可先临时设定环境变量（各模型示例见下文），CCR 会从环境变量读取。

进入 CCR UI 后，在 **Providers** 列表中为每个模型新增配置。**仅需填写 “Base URL” 与 “API Key” 两项**，其它保持默认即可。保存后，可通过 **“新建会话 → 选择模型 → 输入测试消息”** 验证连通性。

**若不想在gui配置，也可以在以下路径打开config.json文件进行配置：**

1.  Windows：
    
    ```text
    %USERPROFILE%\.claude-code-router\config.json
    ```
    
2.  Mac/Linux
    
    ```text
    ~/.claude-code-router/config.json
    ```
    
### 1.3.2 五大模型直连配置

#### 1. Gemini 2.5 Pro

**开通与取 Key**  
[Google Al Studio](https://aistudio.google.com/apikey) → 登录 → 生成 Key（本文称 `<YOUR_GEMINI_API_KEY>`）。

**CCR UI**

*   **Base URL**：`https://generativelanguage.googleapis.com/v1beta/models/`
*   **API Key**：`<YOUR_GEMINI_API_KEY>`
*   **models**：`gemini-2.5-pro`、`gemini-2.5-flash`
*   **transformer**：启用 `gemini`（CCR 内置，将 Claude Code 的消息格式转换为 Gemini 的 `generateContent` 调用）

**`config.json` 片段**

```json
{
  "name": "gemini",
  "api_base_url": "https://generativelanguage.googleapis.com/v1beta/models/",
  "api_key": "<YOUR_GEMINI_API_KEY>",
  "models": ["gemini-2.5-flash", "gemini-2.5-pro"],
  "transformer": { "use": ["gemini"] }
}
```



**应用层代理**  
打开代理后，在 `config.json` 顶层设置 **HTTP 代理**，作用于所有 Provider 的外呼请求：

```json
{
  "PROXY_URL": "http://127.0.0.1:7890",
  "Providers": [
    {
      "name": "gemini",
      "api_base_url": "https://generativelanguage.googleapis.com/v1beta/models/",
      "api_key": "<YOUR_GEMINI_API_KEY>",
      "models": ["gemini-2.5-flash", "gemini-2.5-pro"],
      "transformer": { "use": ["gemini"] }
    }
  ]
}
```

*   `PROXY_URL` 为 CCR 官方支持字段；端口 **7890** 是 Clash/Clash Verge 常见的 **HTTP 代理**端口（请按本地实际端口调整）。
*   修改后建议 `ccr restart`，并确保代理客户端已开启 **System Proxy（系统代理）**。



**连通性测试**  
保存 → `ccr code` → 发送“你好”，正常流式返回即成功。

![](/code/tool/claude/006.png)

#### 2. DeepSeek-V3.1

**开通与取 Key**  
访问 [Deepseek开发平台](https://platform.deepseek.com/api_keys)→ 新建 Key（`<YOUR_DEEPSEEK_API_KEY>`）

**A. Anthropic 模式（推荐写到 /v1/messages）**

*   **Transformer**：**Anthropic**
*   **Base URL**：`https://api.deepseek.com/anthropic/v1/messages`
*   **models**：`deepseek-chat`（如需推理链：`deepseek-reasoner`）

**片段（Anthropic）**

```json
{
  "name": "deepseek-anthropic",
  "api_base_url": "https://api.deepseek.com/anthropic/v1/messages",
  "api_key": "<YOUR_DEEPSEEK_API_KEY>",
  "models": ["deepseek-chat"],
  "transformer": { "use": ["Anthropic"] }
}
```

**B. OpenAI 兼容模式**

*   **Transformer**：**openai**
*   **Base URL**：`https://api.deepseek.com/chat/completions`
*   **models**：`deepseek-chat`, `deepseek-reasoner`

**片段（OpenAI 兼容）**

```json
{
  "name": "deepseek-openai",
  "api_base_url": "https://api.deepseek.com/chat/completions",
  "api_key": "<YOUR_DEEPSEEK_API_KEY>",
  "models": ["deepseek-chat", "deepseek-reasoner"],
}
```

**连通性测试**  
保存 → `ccr code` → 发送“你好”。若报 `completions`/`chat/completions` 调用不匹配或 404，请对照所选模式检查 Base URL 与 Transformer。

* * *

#### 3. GLM-4.5（智谱）

**开通与取 Key**  
访问 [智谱AI开放平台 API 密钥页面](https://open.bigmodel.cn/usercenter/apikeys) → 新建 Key（`<YOUR_ZHIPU_API_KEY>`）

**A. Anthropic 模式**

*   **Transformer**：**Anthropic**
*   **Base URL**：`https://open.bigmodel.cn/api/anthropic/v1/messages`
*   **models**：`glm-4.5`

**片段（Anthropic）**

```json
{
  "name": "zhipu-anthropic",
  "api_base_url": "https://open.bigmodel.cn/api/anthropic/v1/messages",
  "api_key": "<YOUR_ZHIPU_API_KEY>",
  "models": ["glm-4.5"],
  "transformer": { "use": ["Anthropic"] }
}
```

**B. OpenAI 兼容模式**

*   **Transformer**：**openai**
*   **Base URL**：`https://open.bigmodel.cn/api/paas/v4/chat/completions`（注意 **/v4**）
*   **models**：`glm-4.5`

**片段（OpenAI 兼容）**

```json
{
  "name": "zhipu-openai",
  "api_base_url": "https://open.bigmodel.cn/api/paas/v4/chat/completions",
  "api_key": "<YOUR_ZHIPU_API_KEY>",
  "models": ["glm-4.5"],
}
```

**连通性测试**  
保存 → `ccr code` → 发送“你好”。若错误提示你用了 `v1/completions`，请改用 **`/v4/chat/completions`**。

* * *

#### 4. Kimi-K2（0711 preview）

**开通与取 Key**  
访问 [Moonshot AI 开放平台](https://platform.moonshot.cn/console/api-keys) → 新建 Key（`<YOUR_MOONSHOT_API_KEY>`）

> 经过初步的测试，似乎是**Anthropic格式**模型是`kimi-k2-turbo-preview`；**openai格式**模型是`kimi-k2-0711-preview`

**A. Anthropic 模式（推荐写到 /v1/messages）**

*   **Transformer**：**Anthropic**
*   **Base URL**：`https://api.moonshot.cn/anthropic/v1/messages`
*   **models**：`kimi-k2-turbo-preview`

**片段（Anthropic）**

```json
{
  "name": "kimi-anthropic",
  "api_base_url": "https://api.moonshot.cn/anthropic/v1/messages",
  "api_key": "<YOUR_MOONSHOT_API_KEY>",
  "models": ["kimi-k2-turbo-preview"],
  "transformer": { "use": ["Anthropic"] }
}
```

**B. OpenAI 兼容模式**

*   **Transformer**：**openai**
*   **Base URL**：`https://api.moonshot.cn/v1/chat/completions`
*   **models**：`kimi-k2-0711-preview`

**片段（OpenAI 兼容）**

```json
{
  "name": "kimi-openai",
  "api_base_url": "https://api.moonshot.cn/v1/chat/completions",
  "api_key": "<YOUR_MOONSHOT_API_KEY>",
  "models": ["kimi-k2-0711-preview"],
  "transformer": { "use": ["openai"] }
}
```

**连通性测试**  
保存 → `ccr code` → 发送“你好”。若报 `completions`/`chat/completions` 调用不匹配或 404，请对照所选模式检查 Base URL 与 Transformer。

* * *

#### 5. Qwen3-Coder（魔搭 ModelScope）

**开通与取 Key**  
访问 [ModelScope魔搭社区](https://www.modelscope.cn/my/overview)→ 新建 Key（`<YOUR_DEEPSEEK_API_KEY>`）

**CCR UI（OpenAI 兼容）**

*   **Transformer**：**openai**
*   **Base URL**：`https://api-inference.modelscope.cn/v1/chat/completions`
*   **API Key**：`<YOUR_MODELSCOPE_OR_DASHSCOPE_API_KEY>`
*   **models**：`Qwen/Qwen3-Coder-480B-A35B-Instruct`（按实际可用模型名填写）

**`config.json` 片段**

```json
{
  "name": "modelscope",
  "api_base_url": "https://api-inference.modelscope.cn/v1/chat/completions",
  "api_key": "<YOUR_API_KEY>",
  "models": ["Qwen/Qwen3-Coder-480B-A35B-Instruct"],
}
```

* * *

### 1.3.3 连通性测试（统一步骤）

1.  在 CCR UI 保存 Provider；
2.  打开对话：`ccr code`；
3.  发送“你好”或简单指令；
4.  正常收到流式响应即打通。

* * *

### 1.3.5 常见报错速查

*   **401 Unauthorized**：Key 为空/失效/类型不符（如把 DashScope Key 用到非魔搭端点）。
*   **403 Forbidden**：账号或地域未开通对应权限/模型。
*   **429 Too Many Requests**：触发速率/并发限制。
*   **5XX Server Error**：服务端波动，稍后重试或切换可用区。
*   **“This is a chat model and not supported in the v1/completions endpoint”**：  
    你把**聊天模型**发到 `v1/completions` 了；应改用 **`/v1/chat/completions`**（OpenAI 兼容模式）。
*   **404（Anthropic 路径）**：多见于 `…/anthropic` 又被路由层补了一次 `/v1/messages`；**把 Base URL 直接写到 `/v1/messages` 结尾**通常可解。

* * *

### 1.3.6  关于 `/model` 菜单与“自我认知”提示

在 **Claude Code** 的对话框内输入 `/model` 回车，默认只会出现 3 个固定选项（例如 \_Default/Sonnet 4\_、\_Opus\_、\_Opus Plan Mode\_）。**这是内置菜单的限制**。  
但你仍可**手动切换**：直接输入

```bash
/model provider,model
```

例如：

```bash
/model deepseek,deepseek-chat
```

可以正常切到 DeepSeek。  
另外，Claude Code 的**系统提示词**可能让非 Claude 模型在会话开头“自称 Sonnet 4”。**一旦你用 `/model provider,model` 切换成功，模型的“自我认知”就会恢复正常**。


​Claude是完全通过终端进行交互的，其中内置了多种工具，比如文件操作、搜索等。可以理解自然语言并转化为相应的命令执行。
